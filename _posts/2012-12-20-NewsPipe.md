---
title: 'What is NewsPipe?'

layout: null
---

NewsPipe started out as a side project for collecting news articles. Now it is a complete ecosystem for training and deploying GPT-2. It includes many comprehensive tools, which you can use for many other use cases too. Highlights of the newspipe ecosystem:
- [newscrawler](https://github.com/NewsPipe/newscrawler): A  generic news article crawling and information extracting python libary. It utilities popular frameworks newspaper3k, goose and request for extracing the article text. Other informations like title, author, ... are extracted from the RSS feed.
- [newspipe](https://github.com/NewsPipe/newspipe): A scalable news article crawling and information extracting system built on top of Apache-Airflow and [newscrawler](https://github.com/NewsPipe/newscrawler). You can manage your job with the built in dashboard, run the whole system on a Celery cluster or on your server and add news sources by just simply providing a link to the RSS feed or website.
- [gpt2-tfx-pipeline](https://github.com/NewsPipe/gpt2-tfx-pipeline): A complete end-end pipeline for GPT-2 based on Googles framework TensorflowExtended. It includes training from scatch and finetuning from the OpenAI trained models. The data can be loaded from a MongoDB or a file on your local file system. This can also be extended to any data source you need. Training can then be monitored with Tensorboard and trained models can be pushed automatically to a MLFlow model regristy.
- [mlflow-server](https://github.com/NewsPipe/mlflow-server): The complete code for running a encrypted MLFlow server for tracking your models and experiments on your server.

When everything is put together, you will have a continuous learning pipeline for GPT-2. The developers define the news sources that make up the newspaper pipeline and start their crawling jobs. Each crawler stores the crawled news articles in a MongoDB. The GPT-2 training pipeline requests all articles from the MongoDB and trains on them. Each trained model is stored in an MLFlow model register, where a Data Scientist can define the state of a model. When a model is in production state, it is retrieved by our GPT-2 service and used for text generation. The service can be used with a React application. 

![](https://raw.githubusercontent.com/NewsPipe/newspipe.github.io/master/_posts/architecture.png)
