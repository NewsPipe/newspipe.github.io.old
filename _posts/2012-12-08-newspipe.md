---
title: 'newspipe'

layout: null
---
## Introduction
Newspipe is a complete pipeline for collecting online newspaper article. The articles are crawled with NewsCrawler, which gets the informations by extracting and parsing the RSS feed of a website. The extracted informations are then stored in a MongoDB. The whole pipeline is dockerized, thus the user does not need to worry about dependencies. Additionally, docker-compose is available to increase the useability for the user.

## Requirement
- docker
- docker-compose

## Getting Started
Clone our repository and create a `.env` file with all credentials
```
git clone https://github.com/NewsPipe/newspipe.git
cd newspipe
nano .env
```
and paste following template:
```
MONGO_ROOT_USER=devroot
MONGO_ROOT_PASSWORD=devroot
MONGOEXPRESS_LOGIN=dev
MONGOEXPRESS_PASSWORD=dev
POSTGRES_USER=airflow
POSTGRES_PASS=airflow
```
## Start newspipe
To start newspipe, run:
```
docker-compose up
```
- [mongo-express](https://github.com/mongo-express/mongo-express) is running on `localhost:8081`. The MongoDB itself is available on port `27017`. 
- The airflow dashboard is available on `localhost:8080`.
In order to start a DAG, press the trigger next to a DAG name. The triggered DAG will be scheduled automatically

## Adding article sources
Each crawler is defined as DAG in 'dag'. To add a data source, you must therefore add DAGs in the `dags` folder. A DAG is a Python script that contains the settings for an entire crawling pipeline. Use the default example as a template. The DAGs are very simple and straightforward.

```python
import os
import datetime

from dag_factory import create_dag

url = "taz.de" # url of newspaper source

# defining the crawling times
airflow_config = {'schedule_interval': '@hourly', # set a interval, for continuous crawling
                  'start_date': datetime.datetime(2020, 6, 4, 21), # set a date, on which the dag will run
                  'end_date':datetime.datetime(2020, 6, 5, 6), # optinal, set if it is needed
                  }

# create DAG
DAG = create_dag(url=url,
                 airflow_config=airflow_config,
                 name=os.path.basename(__file__))
```

Options for `schedule_interval`:

| preset       | meaning                                                    | cron          |
| ------------ | ---------------------------------------------------------- | ------------- |
| `@once`      | Schedule once and only once                                |               |
| `@hourly`    | Run once an hour at the beginning of the hour              | `0 * * * *`   |
| `@daily`     | Run once a day at midnight                                 | `0 0 * * *`   |
| `@weekly`    | Run once a week at midnight on Sunday morning              | `0 0 * * 0`   |
| `@monthly`   | Run once a month at midnight of the first day of the month | `0 0 1 * *`   |
| `@quarterly` | Run once a quarter at midnight on the first day            | `0 0 1 */3 *` |
| `@yearly`    | Run once a year at midnight of January 1                   | `0 0 1 1 *`   |
